# Material Classification and Size Estimation for Microspheres

This repository contains machine learning and deep learning approaches for material classification and size estimation of microspheres using ultrasonic signals.

## Dataset Overview

The project uses multiple datasets configured in the `DATASETS` dictionary. To access a specific sample, use the structure: `DATASETS[dataset_key]["files"][file_key]`

### Dataset Keys and Available Files

#### `2023_10_04_SAMPLES`
**PMMA pure samples without size variations**
- `pmma_50um`

#### `2024_04_17_SAMPLES`  
**Glass, PE, and Steel pure samples with size variations**
- `glass_50um_large`
- `pe_50um_multi`
- `steel_50um_single`

#### `2024_10_25_SAMPLES`
**Glass, PE, and Steel pure samples with size variations**
- `glass`
- `pe`
- `steel_1`

#### `2024_11_15_MIXED`
**Mixed samples with size variations**
- `mixed_area1`
- `mixed_area2`

### Usage Example
```python
# Access PMMA 50μm sample
dataset = DATASETS["2023_10_04_SAMPLES"]["files"]["pmma_50um"]
file_path = dataset["path"]
params = dataset["params"]
```

## Requirements

### Python Dependencies
- Python >= 3.8
- TensorFlow >= 2.8.0
- scikit-learn
- NumPy
- Pandas
- Matplotlib
- PyYAML
- SciPy

### Hardware Requirements
- **CPU**: Any modern processor (Intel/AMD)
- **Memory**: 8GB RAM minimum, 16GB recommended
- **GPU**: Optional, NVIDIA GPU with CUDA support for faster CNN training
- **Storage**: 15GB free space for models and data

## Installation

1. **Clone the repository**:
   ```bash
   git clone <repository-url>
   cd final_deposit
   ```

2. **Create conda environment**:
   ```bash
   conda create -n mpus python=3.8
   conda activate mpus
   ```

3. **Install dependencies**:
   ```bash
   pip install tensorflow scikit-learn pandas numpy matplotlib pyyaml scipy
   ```

4. **Verify installation**:
   ```bash
   python -c "import tensorflow as tf; print('TensorFlow version:', tf.__version__)"
   ```

## Repository Structure
## Usage

First, download and unzip the dataset from [here](https://zenodo.org/records/18484378), ensuring that the following directory structure is preserved. Material classification can then be evaluated using the provided machine-learning pipelines (`material_classification_ml`) as well as the one-dimensional convolutional neural network implementation (`material_classification_cnn`). Code for particle size estimation is also included. Outputs generated by each method are automatically saved in the root directory of this project.


```
├── data/                              # Dataset storage (gitignored)
│   ├── raw_data/                      # Original MATLAB files
│   ├── all_labeled_signals.csv       # Processed signal data
│   └── material_classification_splits/ # Pre-computed train/val/test splits
├── material_classification_cnn/       # CNN-based material classification
├── material_classification_ml/        # Traditional ML approaches
├── size_estimation/                   # Size estimation models
└── output/                           # Results and visualizations (gitignored)
```



### Parameter Configuration

Each dataset file has optimized parameters for peak extraction set empirically by users for each maximum projection image. You can change these at config file.

| Parameter | Description | Typical Range |
|-----------|-------------|---------------|
| `window_size` | Size of the analysis window | 5-9 |
| `alpha` | Threshold parameter for peak detection | 0.5-0.8 |
| `sigma` | Gaussian smoothing parameter | 0.2-3.0 |
| `box_size` | Size of the displayed bounding box | 6-21 |

## Material Classification

Material classification is performed using both **1D CNN** and **traditional ML algorithms** on the same set of random splits to ensure fair comparison between approaches.

### Evaluation Framework

- **Random Splits**: Pre-computed train/validation/test splits stored in `data/material_classification_splits/`
- **Repeated Evaluation**: `eval_rand.py` runs algorithms multiple times on each split for robust statistical analysis
- **Dual-Level Metrics**: Results are reported at both **signal-level** (individual samples) and **particle-level** (majority voting)

### CNN Approach (`material_classification_cnn/`)

- **Architecture**: 1D Convolutional Neural Network optimized for ultrasonic signal classification
- **Training**: `train.py` - Model training with early stopping and validation
- **Evaluation**: `eval_rand.py` - Repeated evaluation across multiple splits with CPU/GPU support
- **Configuration**: `config.py` - Adjustable parameters for preprocessing, training, and evaluation

### Traditional ML Approach (`material_classification_ml/`)

- **Algorithms**: Random Forest, SVM, Neural Networks, Gradient Boosting, and ensemble methods
- **Features**: Time-domain and frequency-domain feature extraction
- **Evaluation**: `eval_rand.py` - Cross-split validation with particle-level voting
- **Configuration**: `config.yaml` - Model parameters and feature extraction settings

### Visualization and Analysis

- **Bounding Box Visualization**: Use `bbox_prediction.py` for visual analysis of predictions
  - **Requirement**: Trained models must exist in `material_classification_cnn/models/` folder
- **Performance Metrics**: Comprehensive confusion matrices, per-material accuracy, and statistical significance testing
- **Model Comparison**: Fair comparison between CNN and ML approaches using identical data splits

### Configuration Files

Both approaches use configuration files to adjust parameters:
- **CNN**: `material_classification_cnn/config.py` - Training epochs, batch size, model architecture
- **ML**: `material_classification_ml/config.yaml` - Algorithm parameters, feature extraction settings

## Size Estimation

Size estimation is performed using **Multi-Layer Perceptron (MLP)** architecture to predict the size of microspheres from ultrasonic signal features.

### MLP Architecture (`size_estimation/`)

- **Architecture**: Multi-Layer Perceptron optimized for regression tasks
- **Input**: Processed ultrasonic signal features
- **Output**: Predicted particle size (radius) with binned classification approach
- **Evaluation**: `eval_rand.py` - Cross-validation testing on different random seeds

## Getting Started

### Quick Evaluation

Run evaluation scripts to test the models:

```bash
# Activate environment
conda activate mpus

# Material classification using CNN
cd material_classification_cnn
python eval_rand.py

# Material classification using traditional ML
cd ../material_classification_ml
python eval_rand.py

# Size estimation using MLP
cd ../size_estimation
python eval_rand.py
```

### Performance Metrics

- **Material Classification**: Accuracy, Precision, Recall, F1-score (per material and overall)
- **Size Estimation**: MAE, RMSE, R² score, prediction plots



### Evaluation Framework

- **Multi-Seed Testing**: `eval_rand.py` runs the algorithm multiple times on different random seeds for robust statistical analysis
- **Dual-Level Metrics**: Results reported at both **signal-level** (individual trace predictions) and **particle-level** (majority voting across multiple traces per particle)
- **Performance Assessment**: Comprehensive metrics including accuracy, precision, recall, and confusion matrices across size bins

### Configuration

- **Parameter Adjustment**: Use `config.yaml` to modify model parameters, training settings, and evaluation criteria
- **Size Bin Configuration**: Adjustable size ranges for classification-based size estimation
- **Training Parameters**: Epochs, batch size, learning rate, and model architecture can be customized

## Citation

If you use this work in your research, please cite:

```bibtex
@article{zarrabi2026high,
  title={High-frequency ultrasound combined with deep learning enables identification and size estimation of microplastics},
  journal={npj Emerging Contaminants},
  author={Zarrabi, Navid and Strohm, Eric and Rezvani, Hadi and Lisondra, Matthew and Yousefi, Nariman and Saeedi, Sajad and Kolios, Michael},
  year={2026},
  publisher={Nature Publishing Group UK London}
}
```

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Contact

For questions or issues, please contact [email] or open an issue on GitHub.

